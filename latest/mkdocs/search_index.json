{
    "docs": [
        {
            "location": "/", 
            "text": "jInv - A Flexible Flexible Julia Package for PDE Parameter Estimation\n\n\n\n\njInv.Mesh\n\n\nList of types and methods\n\n\n\n\n\n\njInv.LinearSolvers\n\n\nSupported Packages\n\n\nList of types and methods\n\n\n\n\n\n\njInv.InverseSolve\n\n\njInv.ForwardShare\n\n\nList of types and methods\n\n\n\n\n\n\njInv.Utils\n\n\nList of methods\n\n\n\n\n\n\n\n\njInv\n is a flexible framework for PDE parameter estimation in Julia. It provides easy to extend core functions used in PDE-constrained inverse problems.\n\n\n\n\nBuild status\n\n\n  \n \n\n\n\n\nOverview\n\n\njInv consists of five submodules:\n\n\n\n\nForwardShare\n - methods for solving forward problems in parallel.\n\n\nInverseSolve\n - methods commonly used in inverse problems such as misfit functions, regularization and numerical optimization. \n\n\nMesh\n - regular and tensor meshes in 2D and 3D as well as differential operators.\n\n\nLinearSolvers\n - interfaces to sparse and (if installed) direct linear solvers that can be used for solving the discretized PDEs.\n\n\nUtils\n - utility functions\n\n\n\n\n\n\nInstallation\n\n\nIn julia type:\n\n\njulia\n Pkg.clone(\nhttps://github.com/JuliaInv/jInv.jl\n,\njInv\n)\nERROR: jInv already exists\n\njulia\n Pkg.test(\njInv\n)\nINFO: Cloning jInv from https://github.com/JuliaInv/jInv.jl\nINFO: Testing jInv\n3-dimensional regular mesh of size [3,4,5]\nNumber of cells:   60\nNumber of faces:   [80,75,72] = 227\nNumber of edges:   [90,96,100] = 286\nNumber of nodes:   120\nCoordinate origin: [1.2,0.0,0.0]\nDomain size:       [1.2,2.4,0.0,1.1,0.0,2.3]\nCell size:         [0.39999999999999997,0.275,0.45999999999999996]\n2-dimensional regular mesh of size [3,4]\nNumber of cells:   12\nNumber of faces:   [16,15] = 31\nNumber of edges:   [15,16] = 31\nNumber of nodes:   20\nCoordinate origin: [1.2,0.0]\nDomain size:       [1.2,2.4,0.0,1.1]\nCell size:         [0.39999999999999997,0.275]\n3-dimensional tensor mesh of size [4,5,6]\nNumber of cells:   120\nNumber of faces:   [150,144,140] = 434\nNumber of edges:   [168,175,180] = 523\nNumber of nodes:   210\nCoordinate origin: [0.0,0.0,0.0]\nDomain size:       2.4303073987810184m x 3.0807057532001796m x 4.4076512025696335m\nMinimum cell size: 0.27727282554031185m x 0.24845044249587533m x 0.4858066078391947m\nMaximum cell size: 0.9767525826709853m x 0.83816859811106m x 0.9247126195414199m\n==== compare regular and tensor mesh ====\n    test cell-centered axes...passed\n    test nodal axes...passed\n    test cell-centered grid...passed\n    test nodal grid...passed\n    test face grid...passed\n    test edge grid...passed\n    test volume...passed\n    test area...passed\n    test length...passed\n    test counting...passed\n    test nodal gradient matrix...passed\n    test divergence matrix...passed\n    test curl matrix...passed\n    test face average matrix...passed\n    test edge average matrix...passed\n==== test differential operators ====\n    testing differential operators for jInv.Mesh.TensorMesh3D...passed!\n    testing differential operators for jInv.Mesh.RegularMesh...passed!\n    testing differential operators for jInv.Mesh.TensorMesh3D...passed!\n   test getInterpolationMatrix (RegularMesh) ...  dim=2 dim=3 passed\n   test getInterpolationMatrix (TensorMesh) ... passed\n==== test differential operators ====\n    testing nodal averaging for jInv.Mesh.TensorMesh3D...passed!\n    testing nodal averaging for jInv.Mesh.RegularMesh...passed!\n    testing nodal averaging for jInv.Mesh.TensorMesh3D...passed!\n    testing nodal averaging for jInv.Mesh.RegularMesh...passed!\n==== test persistency of linear operators ====\n Mesh: All tests passed!\ntest prepareMesh2Mesh\ncompare remote versions with local ones\ntest interpGlobal2Local\ntest interpLocal2Global\n Testing module Utils\n   Testing sparseUtils\n   sparseUtils: All tests passed!\ntesting sortpermFast\ntesting uniqueidx\n   test checkDerivative ...        h           E0          E1          O1          O2     OK?\n1.000e-01   1.699e-01   7.906e-03   0.000e+00   0.000e+00       0\n1.000e-02   1.770e-02   7.906e-05   9.822e-01   2.000e+00       1\n1.000e-03   1.777e-03   7.906e-07   9.983e-01   2.000e+00       1\n1.000e-04   1.778e-04   7.906e-09   9.998e-01   2.000e+00       1\n1.000e-05   1.778e-05   7.906e-11   1.000e+00   2.000e+00       1\n1.000e-06   1.778e-06   7.906e-13   1.000e+00   2.000e+00       1\n1.000e-07   1.778e-07   7.762e-15   1.000e+00   2.008e+00       1\n1.000e-08   1.778e-08   3.610e-16   1.000e+00   1.332e+00       1\n1.000e-09   1.778e-09   1.805e-16   1.000e+00   3.010e-01       1\n1.000e-10   1.778e-10   1.805e-16   1.000e+00   0.000e+00       1\n        h          E0          E1          O1          O2     OK?\n1.000e-01   9.874e-02   4.048e-03   0.000e+00   0.000e+00       0\n1.000e-02   9.999e-03   4.048e-05   9.945e-01   2.000e+00       1\n1.000e-03   1.001e-03   4.048e-07   9.994e-01   2.000e+00       1\n1.000e-04   1.001e-04   4.048e-09   9.999e-01   2.000e+00       1\n1.000e-05   1.001e-05   4.048e-11   1.000e+00   2.000e+00       1\n1.000e-06   1.001e-06   4.048e-13   1.000e+00   2.000e+00       1\n1.000e-07   1.001e-07   4.072e-15   1.000e+00   1.997e+00       1\n1.000e-08   1.001e-08   1.192e-16   1.000e+00   1.534e+00       1\n1.000e-09   1.001e-09   7.416e-17   1.000e+00   2.061e-01       1\n1.000e-10   1.001e-10   6.064e-17   1.000e+00   8.738e-02       1\npassed\n Utils: All tests passed\n test module InverseSolve\n        checkDerivative of jInv.InverseSolve.expMod\n        checkDerivative of jInv.InverseSolve.boundMod\n        checkDerivative of jInv.InverseSolve.fMod\nGradient test for jInv.InverseSolve.SSDFun (real)\nGradient test for jInv.InverseSolve.HuberFun (real)\nHessian test for jInv.InverseSolve.SSDFun (real)\nGradient test for jInv.InverseSolve.SSDFun (complex)\nHessian test for jInv.InverseSolve.SSDFun (complex)\nWARNING: skipped\ncheckDerivative of (anonymous function)\ncheckDerivative of (anonymous function)\ncheckDerivative of jInv.InverseSolve.smallnessReg\ncheckDerivative of (anonymous function)\ncheckDerivative of jInv.InverseSolve.wdiffusionRegNodal\ncheckDerivative of jInv.InverseSolve.wTVRegNodal\ncheckDerivative of jInv.InverseSolve.logBarrier\ncheckDerivative of jInv.InverseSolve.logBarrierSquared\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   1.56e+02    0.00e+00    1.00e+00    1.00e+00      0\n   .1   4.81e+00    5.41e+00            6.56e-02\n  2.0   4.81e+00    5.41e+00    1.00e+00    6.56e-02      1\n   .1   3.67e+00    5.94e+00            6.17e-02\n  3.0   3.67e+00    5.94e+00    1.00e+00    6.17e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\n  4.0   3.67e+00    5.91e+00    1.00e+00    6.15e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\n  5.0   3.67e+00    5.91e+00    1.00e+00    6.15e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\nprojGNCG iterated maxIter=5 times but reached only stepNorm of 0.00022480318483963924 instead 0.0001.\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   1.56e+02    0.00e+00    1.00e+00    1.00e+00      0\n   .1   4.81e+00    5.41e+00            6.56e-02\n  2.0   4.81e+00    5.41e+00    1.00e+00    6.56e-02      1\n   .1   3.67e+00    5.94e+00            6.17e-02\n  3.0   3.67e+00    5.94e+00    1.00e+00    6.17e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\n  4.0   3.67e+00    5.91e+00    1.00e+00    6.15e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\n  5.0   3.67e+00    5.91e+00    1.00e+00    6.15e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\nprojGNCG iterated maxIter=5 times but reached only stepNorm of 0.00022480318483963924 instead 0.0001.\n InverseSolve: All tests passed!\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.39e+01    0.00e+00    1.00e+00    1.00e+00      0\n   .1   1.42e+00    3.18e+00            1.93e-01\n  2.0   1.42e+00    3.18e+00    1.00e+00    1.93e-01      0\n   .1   1.34e+00    3.23e+00            1.91e-01\n  3.0   1.34e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\n  4.0   1.35e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\n  5.0   1.35e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\nprojGNCG reached desired accuracy at iteration 5.\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.39e+01    0.00e+00    1.00e+00    1.00e+00      0\n   .1   1.42e+00    3.18e+00            1.93e-01\n  2.0   1.42e+00    3.18e+00    1.00e+00    1.93e-01      0\n   .1   1.34e+00    3.23e+00            1.91e-01\n  3.0   1.34e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\n  4.0   1.35e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\n  5.0   1.35e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\nprojGNCG reached desired accuracy at iteration 5.\ni.LS           F           R    alpha[1]       Jc/J0\n  1.0   2.39e+01    0.00e+00    1.00e+00    1.00e+00\n   .1   1.42e+00    3.19e+00            1.93e-01\n  2.0   1.42e+00    3.19e+00    1.00e+00    1.93e-01\n   .1   1.34e+00    3.23e+00            1.91e-01\n  3.0   1.34e+00    3.23e+00    1.00e+00    1.91e-01\n   .1   1.36e+00    3.22e+00            1.91e-01\n  4.0   1.36e+00    3.22e+00    1.00e+00    1.91e-01\n   .1   1.35e+00    3.22e+00            1.91e-01\n  5.0   1.35e+00    3.22e+00    1.00e+00    1.91e-01\n   .1   1.35e+00    3.22e+00            1.91e-01\nbarrierGNCG iterated maxIter=5 times but reached only stepNorm of 0.00011414785709251696 instead 0.0001.\ni.LS           F           R    alpha[1]       Jc/J0\n  1.0   2.39e+01    0.00e+00    1.00e+00    1.00e+00\n   .1   1.42e+00    3.19e+00            1.93e-01\n  2.0   1.42e+00    3.19e+00    1.00e+00    1.93e-01\n   .1   1.34e+00    3.23e+00            1.91e-01\n  3.0   1.34e+00    3.23e+00    1.00e+00    1.91e-01\n   .1   1.36e+00    3.22e+00            1.91e-01\n  4.0   1.36e+00    3.22e+00    1.00e+00    1.91e-01\n   .1   1.35e+00    3.22e+00            1.91e-01\n  5.0   1.35e+00    3.22e+00    1.00e+00    1.91e-01\n   .1   1.35e+00    3.22e+00            1.91e-01\nbarrierGNCG iterated maxIter=5 times but reached only stepNorm of 0.00011414785709251696 instead 0.0001.\nStarting projGNCG minimization with alpha 1 of 3\nalpha = 100.0\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.39e+01    0.00e+00    1.00e+02    1.00e+00      0\n   .1   2.16e+01    1.14e+00            9.49e-01\n  2.0   2.16e+01    1.14e+00    1.00e+02    9.49e-01      0\n   .1   2.16e+01    1.14e+00            9.49e-01\nprojGNCG iterated maxIter=2 times but reached only stepNorm of 0.000971984065644989 instead 0.0001.\n[23.89747298876634,21.551561877815104,21.55183013784889]\nStarting projGNCG minimization with alpha 2 of 3\nalpha = 10.0\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.16e+01    0.00e+00    1.00e+01    1.00e+00      0\n   .1   9.77e+00    4.59e+00            6.66e-01\n  2.0   9.77e+00    4.59e+00    1.00e+01    6.66e-01      0\n   .1   9.77e+00    4.58e+00            6.66e-01\nprojGNCG iterated maxIter=2 times but reached only stepNorm of 0.004130041022003539 instead 0.0001.\n[21.55183013784889,9.77067092202882,9.773339478395236]\niteratedTikhonov exiting after reaching desired misfit\nStarting projGNCG minimization with alpha 1 of 3\nalpha = 100.0\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.39e+01    0.00e+00    1.00e+02    1.00e+00      0\n   .1   2.16e+01    1.14e+00            9.49e-01\n  2.0   2.16e+01    1.14e+00    1.00e+02    9.49e-01      0\n   .1   2.16e+01    1.14e+00            9.49e-01\nprojGNCG iterated maxIter=2 times but reached only stepNorm of 0.000971984065644989 instead 0.0001.\n[23.89747298876634,21.551561877815104,21.55183013784889]\nStarting projGNCG minimization with alpha 2 of 3\nalpha = 10.0\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.16e+01    0.00e+00    1.00e+01    1.00e+00      0\n   .1   9.77e+00    4.59e+00            6.66e-01\n  2.0   9.77e+00    4.59e+00    1.00e+01    6.66e-01      0\n   .1   9.77e+00    4.58e+00            6.66e-01\nprojGNCG iterated maxIter=2 times but reached only stepNorm of 0.004130041022003539 instead 0.0001.\n[21.55183013784889,9.77067092202882,9.773339478395236]\niteratedTikhonov exiting after reaching desired misfit\n===  Example 2D DivSigGrad ====\ncg achieved desired tolerance at iteration 8. Residual norm is 5.17e-06.\nbcgstb achieved desired tolerance at iteration 4. Residual norm is 6.57e-05.\n===  Test for nonsymmetric matrices ====\n===  Example 2D DivSigGrad ====\nblockCG achieved desired tolerance at iteration 6. Residual norm is 3.34e-05.\nblockBiCGSTB achieved desired tolerance at iteration 3. Residual norm is 1.61e-04.\n===  Test for nonsymmetric matrices ====\n===  Test Julia Wrapper: Symmetric ====\n===  Test Julia Wrapper: nonsymmetric matrices ====\n===  End Test Julia Wrapper ====\n\n\n\n\n\n\nRequirements\n\n\njInv is developed using Julia versions 0.4.x.\n\n\n\n\nKrylovMethods.jl\n  - iterative methods for solving (sparse) linear systems. \n\n\n\n\nAdditional (optional) packages for higher performance. \njInv\n detects automatically if these packages are installed and uses them by default.\n\n\n\n\nMUMPS.jl\n - wrapper for MUMPS. Used as a direct PDE solver. \n\n\nParSpMatVec.jl\n - shared memory implementation for sparse matrix vector products.", 
            "title": "Home"
        }, 
        {
            "location": "/#jinv-a-flexible-flexible-julia-package-for-pde-parameter-estimation", 
            "text": "jInv.Mesh  List of types and methods    jInv.LinearSolvers  Supported Packages  List of types and methods    jInv.InverseSolve  jInv.ForwardShare  List of types and methods    jInv.Utils  List of methods     jInv  is a flexible framework for PDE parameter estimation in Julia. It provides easy to extend core functions used in PDE-constrained inverse problems.", 
            "title": "jInv - A Flexible Flexible Julia Package for PDE Parameter Estimation"
        }, 
        {
            "location": "/#build-status", 
            "text": "", 
            "title": "Build status"
        }, 
        {
            "location": "/#overview", 
            "text": "jInv consists of five submodules:   ForwardShare  - methods for solving forward problems in parallel.  InverseSolve  - methods commonly used in inverse problems such as misfit functions, regularization and numerical optimization.   Mesh  - regular and tensor meshes in 2D and 3D as well as differential operators.  LinearSolvers  - interfaces to sparse and (if installed) direct linear solvers that can be used for solving the discretized PDEs.  Utils  - utility functions", 
            "title": "Overview"
        }, 
        {
            "location": "/#installation", 
            "text": "In julia type:  julia  Pkg.clone( https://github.com/JuliaInv/jInv.jl , jInv )\nERROR: jInv already exists\n\njulia  Pkg.test( jInv )\nINFO: Cloning jInv from https://github.com/JuliaInv/jInv.jl\nINFO: Testing jInv\n3-dimensional regular mesh of size [3,4,5]\nNumber of cells:   60\nNumber of faces:   [80,75,72] = 227\nNumber of edges:   [90,96,100] = 286\nNumber of nodes:   120\nCoordinate origin: [1.2,0.0,0.0]\nDomain size:       [1.2,2.4,0.0,1.1,0.0,2.3]\nCell size:         [0.39999999999999997,0.275,0.45999999999999996]\n2-dimensional regular mesh of size [3,4]\nNumber of cells:   12\nNumber of faces:   [16,15] = 31\nNumber of edges:   [15,16] = 31\nNumber of nodes:   20\nCoordinate origin: [1.2,0.0]\nDomain size:       [1.2,2.4,0.0,1.1]\nCell size:         [0.39999999999999997,0.275]\n3-dimensional tensor mesh of size [4,5,6]\nNumber of cells:   120\nNumber of faces:   [150,144,140] = 434\nNumber of edges:   [168,175,180] = 523\nNumber of nodes:   210\nCoordinate origin: [0.0,0.0,0.0]\nDomain size:       2.4303073987810184m x 3.0807057532001796m x 4.4076512025696335m\nMinimum cell size: 0.27727282554031185m x 0.24845044249587533m x 0.4858066078391947m\nMaximum cell size: 0.9767525826709853m x 0.83816859811106m x 0.9247126195414199m\n==== compare regular and tensor mesh ====\n    test cell-centered axes...passed\n    test nodal axes...passed\n    test cell-centered grid...passed\n    test nodal grid...passed\n    test face grid...passed\n    test edge grid...passed\n    test volume...passed\n    test area...passed\n    test length...passed\n    test counting...passed\n    test nodal gradient matrix...passed\n    test divergence matrix...passed\n    test curl matrix...passed\n    test face average matrix...passed\n    test edge average matrix...passed\n==== test differential operators ====\n    testing differential operators for jInv.Mesh.TensorMesh3D...passed!\n    testing differential operators for jInv.Mesh.RegularMesh...passed!\n    testing differential operators for jInv.Mesh.TensorMesh3D...passed!\n   test getInterpolationMatrix (RegularMesh) ...  dim=2 dim=3 passed\n   test getInterpolationMatrix (TensorMesh) ... passed\n==== test differential operators ====\n    testing nodal averaging for jInv.Mesh.TensorMesh3D...passed!\n    testing nodal averaging for jInv.Mesh.RegularMesh...passed!\n    testing nodal averaging for jInv.Mesh.TensorMesh3D...passed!\n    testing nodal averaging for jInv.Mesh.RegularMesh...passed!\n==== test persistency of linear operators ====\n Mesh: All tests passed!\ntest prepareMesh2Mesh\ncompare remote versions with local ones\ntest interpGlobal2Local\ntest interpLocal2Global\n Testing module Utils\n   Testing sparseUtils\n   sparseUtils: All tests passed!\ntesting sortpermFast\ntesting uniqueidx\n   test checkDerivative ...        h           E0          E1          O1          O2     OK?\n1.000e-01   1.699e-01   7.906e-03   0.000e+00   0.000e+00       0\n1.000e-02   1.770e-02   7.906e-05   9.822e-01   2.000e+00       1\n1.000e-03   1.777e-03   7.906e-07   9.983e-01   2.000e+00       1\n1.000e-04   1.778e-04   7.906e-09   9.998e-01   2.000e+00       1\n1.000e-05   1.778e-05   7.906e-11   1.000e+00   2.000e+00       1\n1.000e-06   1.778e-06   7.906e-13   1.000e+00   2.000e+00       1\n1.000e-07   1.778e-07   7.762e-15   1.000e+00   2.008e+00       1\n1.000e-08   1.778e-08   3.610e-16   1.000e+00   1.332e+00       1\n1.000e-09   1.778e-09   1.805e-16   1.000e+00   3.010e-01       1\n1.000e-10   1.778e-10   1.805e-16   1.000e+00   0.000e+00       1\n        h          E0          E1          O1          O2     OK?\n1.000e-01   9.874e-02   4.048e-03   0.000e+00   0.000e+00       0\n1.000e-02   9.999e-03   4.048e-05   9.945e-01   2.000e+00       1\n1.000e-03   1.001e-03   4.048e-07   9.994e-01   2.000e+00       1\n1.000e-04   1.001e-04   4.048e-09   9.999e-01   2.000e+00       1\n1.000e-05   1.001e-05   4.048e-11   1.000e+00   2.000e+00       1\n1.000e-06   1.001e-06   4.048e-13   1.000e+00   2.000e+00       1\n1.000e-07   1.001e-07   4.072e-15   1.000e+00   1.997e+00       1\n1.000e-08   1.001e-08   1.192e-16   1.000e+00   1.534e+00       1\n1.000e-09   1.001e-09   7.416e-17   1.000e+00   2.061e-01       1\n1.000e-10   1.001e-10   6.064e-17   1.000e+00   8.738e-02       1\npassed\n Utils: All tests passed\n test module InverseSolve\n        checkDerivative of jInv.InverseSolve.expMod\n        checkDerivative of jInv.InverseSolve.boundMod\n        checkDerivative of jInv.InverseSolve.fMod\nGradient test for jInv.InverseSolve.SSDFun (real)\nGradient test for jInv.InverseSolve.HuberFun (real)\nHessian test for jInv.InverseSolve.SSDFun (real)\nGradient test for jInv.InverseSolve.SSDFun (complex)\nHessian test for jInv.InverseSolve.SSDFun (complex)\nWARNING: skipped\ncheckDerivative of (anonymous function)\ncheckDerivative of (anonymous function)\ncheckDerivative of jInv.InverseSolve.smallnessReg\ncheckDerivative of (anonymous function)\ncheckDerivative of jInv.InverseSolve.wdiffusionRegNodal\ncheckDerivative of jInv.InverseSolve.wTVRegNodal\ncheckDerivative of jInv.InverseSolve.logBarrier\ncheckDerivative of jInv.InverseSolve.logBarrierSquared\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   1.56e+02    0.00e+00    1.00e+00    1.00e+00      0\n   .1   4.81e+00    5.41e+00            6.56e-02\n  2.0   4.81e+00    5.41e+00    1.00e+00    6.56e-02      1\n   .1   3.67e+00    5.94e+00            6.17e-02\n  3.0   3.67e+00    5.94e+00    1.00e+00    6.17e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\n  4.0   3.67e+00    5.91e+00    1.00e+00    6.15e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\n  5.0   3.67e+00    5.91e+00    1.00e+00    6.15e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\nprojGNCG iterated maxIter=5 times but reached only stepNorm of 0.00022480318483963924 instead 0.0001.\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   1.56e+02    0.00e+00    1.00e+00    1.00e+00      0\n   .1   4.81e+00    5.41e+00            6.56e-02\n  2.0   4.81e+00    5.41e+00    1.00e+00    6.56e-02      1\n   .1   3.67e+00    5.94e+00            6.17e-02\n  3.0   3.67e+00    5.94e+00    1.00e+00    6.17e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\n  4.0   3.67e+00    5.91e+00    1.00e+00    6.15e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\n  5.0   3.67e+00    5.91e+00    1.00e+00    6.15e-02      0\n   .1   3.67e+00    5.91e+00            6.15e-02\nprojGNCG iterated maxIter=5 times but reached only stepNorm of 0.00022480318483963924 instead 0.0001.\n InverseSolve: All tests passed!\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.39e+01    0.00e+00    1.00e+00    1.00e+00      0\n   .1   1.42e+00    3.18e+00            1.93e-01\n  2.0   1.42e+00    3.18e+00    1.00e+00    1.93e-01      0\n   .1   1.34e+00    3.23e+00            1.91e-01\n  3.0   1.34e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\n  4.0   1.35e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\n  5.0   1.35e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\nprojGNCG reached desired accuracy at iteration 5.\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.39e+01    0.00e+00    1.00e+00    1.00e+00      0\n   .1   1.42e+00    3.18e+00            1.93e-01\n  2.0   1.42e+00    3.18e+00    1.00e+00    1.93e-01      0\n   .1   1.34e+00    3.23e+00            1.91e-01\n  3.0   1.34e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\n  4.0   1.35e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\n  5.0   1.35e+00    3.23e+00    1.00e+00    1.91e-01      0\n   .1   1.35e+00    3.23e+00            1.91e-01\nprojGNCG reached desired accuracy at iteration 5.\ni.LS           F           R    alpha[1]       Jc/J0\n  1.0   2.39e+01    0.00e+00    1.00e+00    1.00e+00\n   .1   1.42e+00    3.19e+00            1.93e-01\n  2.0   1.42e+00    3.19e+00    1.00e+00    1.93e-01\n   .1   1.34e+00    3.23e+00            1.91e-01\n  3.0   1.34e+00    3.23e+00    1.00e+00    1.91e-01\n   .1   1.36e+00    3.22e+00            1.91e-01\n  4.0   1.36e+00    3.22e+00    1.00e+00    1.91e-01\n   .1   1.35e+00    3.22e+00            1.91e-01\n  5.0   1.35e+00    3.22e+00    1.00e+00    1.91e-01\n   .1   1.35e+00    3.22e+00            1.91e-01\nbarrierGNCG iterated maxIter=5 times but reached only stepNorm of 0.00011414785709251696 instead 0.0001.\ni.LS           F           R    alpha[1]       Jc/J0\n  1.0   2.39e+01    0.00e+00    1.00e+00    1.00e+00\n   .1   1.42e+00    3.19e+00            1.93e-01\n  2.0   1.42e+00    3.19e+00    1.00e+00    1.93e-01\n   .1   1.34e+00    3.23e+00            1.91e-01\n  3.0   1.34e+00    3.23e+00    1.00e+00    1.91e-01\n   .1   1.36e+00    3.22e+00            1.91e-01\n  4.0   1.36e+00    3.22e+00    1.00e+00    1.91e-01\n   .1   1.35e+00    3.22e+00            1.91e-01\n  5.0   1.35e+00    3.22e+00    1.00e+00    1.91e-01\n   .1   1.35e+00    3.22e+00            1.91e-01\nbarrierGNCG iterated maxIter=5 times but reached only stepNorm of 0.00011414785709251696 instead 0.0001.\nStarting projGNCG minimization with alpha 1 of 3\nalpha = 100.0\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.39e+01    0.00e+00    1.00e+02    1.00e+00      0\n   .1   2.16e+01    1.14e+00            9.49e-01\n  2.0   2.16e+01    1.14e+00    1.00e+02    9.49e-01      0\n   .1   2.16e+01    1.14e+00            9.49e-01\nprojGNCG iterated maxIter=2 times but reached only stepNorm of 0.000971984065644989 instead 0.0001.\n[23.89747298876634,21.551561877815104,21.55183013784889]\nStarting projGNCG minimization with alpha 2 of 3\nalpha = 10.0\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.16e+01    0.00e+00    1.00e+01    1.00e+00      0\n   .1   9.77e+00    4.59e+00            6.66e-01\n  2.0   9.77e+00    4.59e+00    1.00e+01    6.66e-01      0\n   .1   9.77e+00    4.58e+00            6.66e-01\nprojGNCG iterated maxIter=2 times but reached only stepNorm of 0.004130041022003539 instead 0.0001.\n[21.55183013784889,9.77067092202882,9.773339478395236]\niteratedTikhonov exiting after reaching desired misfit\nStarting projGNCG minimization with alpha 1 of 3\nalpha = 100.0\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.39e+01    0.00e+00    1.00e+02    1.00e+00      0\n   .1   2.16e+01    1.14e+00            9.49e-01\n  2.0   2.16e+01    1.14e+00    1.00e+02    9.49e-01      0\n   .1   2.16e+01    1.14e+00            9.49e-01\nprojGNCG iterated maxIter=2 times but reached only stepNorm of 0.000971984065644989 instead 0.0001.\n[23.89747298876634,21.551561877815104,21.55183013784889]\nStarting projGNCG minimization with alpha 2 of 3\nalpha = 10.0\ni.LS           F           R    alpha[1]       Jc/J0     #Active\n  1.0   2.16e+01    0.00e+00    1.00e+01    1.00e+00      0\n   .1   9.77e+00    4.59e+00            6.66e-01\n  2.0   9.77e+00    4.59e+00    1.00e+01    6.66e-01      0\n   .1   9.77e+00    4.58e+00            6.66e-01\nprojGNCG iterated maxIter=2 times but reached only stepNorm of 0.004130041022003539 instead 0.0001.\n[21.55183013784889,9.77067092202882,9.773339478395236]\niteratedTikhonov exiting after reaching desired misfit\n===  Example 2D DivSigGrad ====\ncg achieved desired tolerance at iteration 8. Residual norm is 5.17e-06.\nbcgstb achieved desired tolerance at iteration 4. Residual norm is 6.57e-05.\n===  Test for nonsymmetric matrices ====\n===  Example 2D DivSigGrad ====\nblockCG achieved desired tolerance at iteration 6. Residual norm is 3.34e-05.\nblockBiCGSTB achieved desired tolerance at iteration 3. Residual norm is 1.61e-04.\n===  Test for nonsymmetric matrices ====\n===  Test Julia Wrapper: Symmetric ====\n===  Test Julia Wrapper: nonsymmetric matrices ====\n===  End Test Julia Wrapper ====", 
            "title": "Installation"
        }, 
        {
            "location": "/#requirements", 
            "text": "jInv is developed using Julia versions 0.4.x.   KrylovMethods.jl   - iterative methods for solving (sparse) linear systems.    Additional (optional) packages for higher performance.  jInv  detects automatically if these packages are installed and uses them by default.   MUMPS.jl  - wrapper for MUMPS. Used as a direct PDE solver.   ParSpMatVec.jl  - shared memory implementation for sparse matrix vector products.", 
            "title": "Requirements"
        }, 
        {
            "location": "/Mesh/", 
            "text": "jInv.Mesh\n\n\nCurrently, the \nMesh\n submodule methods and provides operators on regular and tensor meshes but is easily extensible. All meshes are instances of \nAbstractMesh\n. \n\n\n\n\nList of types and methods\n\n\n#\n\n\njInv.Mesh.RegularMesh\n \n \nType\n.\n\n\ntype jInv.Mesh.RegularMesh \n: AbstractTensorMesh\n\nRegular mesh in 1D, 2D, and 3D\n\nFields:\n\n    domain::Vector{Float64}  - physical domain [min(x1) max(x1) min(x2) max(x2)]\n    h::Vector{Float64}       - cell size\n    x0::Vector{Float64}      - origin\n    dim::Int                 - dimension of mesh\n    n::Vector{Int64}         - number of cells in each dimension\n    nc::Int                  - total number of cells\n    nf::Vector{Int64}        - number of faces in each dimension\n    ne::Vector{Int64}        - number of edges in each dimension\n\n\n    Persistent Operators:\n\n    Operators should not be accessed directly. They will be built, if needed,\n    when accessing them using specified method. clear!(M) will release all \n    memory.\n\n        Div::SparseMatrixCSC    - divergence (faces -\n cell-centers)\n                                  Access via: getDivergenceMatrix(M)\n        Grad::SparseMatrixCSC   - gradient (nodal -\n edges)\n                                  Access via: getNodalGradientMatrix(M)\n        Curl::SparseMatrixCSC   - curl (edges -\n faces)\n                                  Access via: getCurlMatrix(M)\n        Af::SparseMatrixCSC     - face average (faces -\n cell-centers)\n                                  Access via: getFaceAverageMatrix(M)\n        Ae::SparseMatrixCSC     - edge average (edges -\n cell-centers)\n                                  Access via: getEdgeAverageMatrix(M)\n        An::SparseMatrixCSC     - nodal average (nodes -\n cell-centers)\n                                  Access via: getNodalAverageMatrix(M)\n        V::SparseMatrixCSC      - cell volumes (diagonal matrix)\n                                  Access via: getVolume(M)\n        F::SparseMatrixCSC      - face area (diagonal matrix)\n                                  Access via: getFaceArea(M)\n        L::SparseMatrixCSC      - edge length (diagonal matrix)\n                                  Access via: getLength(M)\n        Vi::SparseMatrixCSC     - inverse cell volumes (diagonal matrix)\n                                  Access via: getVolumeInv(M)\n        Fi::SparseMatrixCSC     - inverse face area (diagonal matrix)\n                                  Access via: getFaceAreaInv(M)\n        Li::SparseMatrixCSC     - inverse edge length (diagonal matrix)\n                                  Access via: getLengthAreaInv(M)\n        nLap::SparseMatrixCSC   - nodal Laplacian\n                                  Access via: getNodalLaplacian(M)\n\nExamples:\nM2D  = getRegularMesh([1.2 2.4 2.2 5.0],[3,4])  \nM3D  = getRegularMesh([1.2 2.4 2.2 5.0 0 1],[3,4,7])\n\n\n\n\n#\n\n\njInv.Mesh.TensorMesh3D\n \n \nType\n.\n\n\ntype jInv.Mesh.TensorMesh3D \n: AbstractTensorMesh\n\nFields:\n\n    h1::Vector{Float64}     - cell size in x1 direction\n    h2::Vector{Float64}     - cell size in x2 direction\n    h3::Vector{Float64}     - cell size in x3 direction\n    x0::Vector{Float64}     - origin\n    dim::Int                - dimension (dim=3)\n    n::Vector{Int64}        - number of cells in each direction\n    nc::Int                 - nc total number of cells (nc=prod(n))\n    nf::Vector{Int64}       - number of faces\n    ne::Vector{Int64}       - number of edges\n\nPersistent Operators:\n\nOperators should not be accessed directly. They will be built, if needed,\nwhen accessing them using specified method. clear!(M) will release all \nmemory.\n\n    Div::SparseMatrixCSC    - divergence (faces -\n cell-centers)\n                              Access via: getDivergenceMatrix(M)\n    Grad::SparseMatrixCSC   - gradient (nodal -\n edges)\n                              Access via: getNodalGradientMatrix(M)\n    Curl::SparseMatrixCSC   - curl (edges -\n faces)\n                              Access via: getCurlMatrix(M)\n    Af::SparseMatrixCSC     - face average (faces -\n cell-centers)\n                              Access via: getFaceAverageMatrix(M)\n    Ae::SparseMatrixCSC     - edge average (edges -\n cell-centers)\n                              Access via: getEdgeAverageMatrix(M)\n    An::SparseMatrixCSC     - nodal average (nodes -\n cell-centers)\n                              Access via: getNodalAverageMatrix(M)\n    V::SparseMatrixCSC      - cell volumes (diagonal matrix)\n                              Access via: getVolume(M)\n    F::SparseMatrixCSC      - face area (diagonal matrix)\n                              Access via: getFaceArea(M)\n    L::SparseMatrixCSC      - edge length (diagonal matrix)\n                              Access via: getLength(M)\n    Vi::SparseMatrixCSC     - inverse cell volumes (diagonal matrix)\n                              Access via: getVolumeInv(M)\n    Fi::SparseMatrixCSC     - inverse face area (diagonal matrix)\n                              Access via: getFaceAreaInv(M)\n    Li::SparseMatrixCSC     - inverse edge length (diagonal matrix)\n                              Access via: getLengthAreaInv(M)\n    nLap::SparseMatrixCSC   - nodal Laplacian\n                              Access via: getNodalLaplacian(M)\n\nExample: \n\nh1 = rand(4); h2 = rand(6); h3 = rand(5);\nM  = getTensorMesh2D(h1,h2,h3)\n\n\n\n\n#\n\n\njInv.Mesh.getEdgeAverageMatrix\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getEdgeAverageMatrix\n\n\nReturns Edge-to-CellCenter average matrix from Mesh.Ae. \nMatrix is constructed if Mesh.Ae is empty. \n\nFor 3D Mesh: Ae = [A1 A2 A3]\n\nInput: \n    Mesh::Abstract Mesh\n\n\n\n\n#\n\n\njInv.Mesh.getEdgeMassMatrix\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getEdgeMassMatrix(mesh,sigma)\n\nReturns mass matrix on cell edges, weighted by vector sigma.\nMatrix is always constructed. Uses pre-constructed edge averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       sigma::Vector\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}\n\n\n\n\n#\n\n\njInv.Mesh.getFaceAverageMatrix\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getFaceAverageMatrix\n\n\nReturns Face-to-CellCenter average matrix from Mesh.Af. \nMatrix is constructed if Mesh.Af is empty. \n\nFor 2D Mesh: Af = [A1 A2]\nFor 3D Mesh: Af = [A1 A2 A3]\n\nInput: \n    Mesh::Abstract Mesh\n\n\n\n\n#\n\n\njInv.Mesh.getFaceMassMatrix\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getFaceMassMatrix(Mesh,sigma)\n\nReturns face mass matrix, weighted by vector sigma. \nMatrix is always constructed. Uses pre-constructed face averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       sigma::Vector\n\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}\n\n\n\n\n#\n\n\njInv.Mesh.getInterpolationMatrix\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getInterpolationMatrix\n\n\ncomputes bi/trilinear interpolation matrix P for cell-centered data from Mesh1 to Mesh2. If I1 is a cell-centerd discretization of some function  on Mesh1 then, its interpolant on Mesh2 is given by\n\n\nI2 = P*I1\n\n\nRequired Input:\n\n\nM1::AbstractTensorMesh \nM2::AbstractTensorMesh\n\n\n\n\nExample:\n\n\nIn mesh-decoupling, we use different meshes for the inverse solution\nand the different forward problems. \n\nMesh2Mesh = getInterpolationMatrix(Minv,Mfor)\n\n\n\n\n#\n\n\njInv.Mesh.getNodalAverageMatrix\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getNodalAverageMatrix\n\n\nReturns Nodal-to-CellCenter average matrix from Mesh.An. \nMatrix is constructed if Mesh.An is empty. \n\nInput: \n    Mesh::Abstract Mesh\n\n\n\n\n#\n\n\njInv.Mesh.getNodalMassMatrix\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getNodalMassMatrix(Mesh,sigma)\n\nReturns nodal mass matrix, weighted by vector sigma. \nMatrix is always constructed. Uses pre-constructed nodal averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       sigma::Vector\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}\n\n\n\n\n#\n\n\njInv.Mesh.getRegularMesh\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getRegularMesh\n\nConstructs regular mesh\n\nInput: \n    domain - physical domain rectangular\n    n      - number of cells in each dimension\n\nExamples:\nM2D  = getRegularMesh([1.2 2.4 2.2 5.0],[3,4])  \nM3D  = getRegularMesh([1.2 2.4 2.2 5.0 0 1],[3,4,7])\n\n\n\n\n#\n\n\njInv.Mesh.getTensorMesh3D\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getTensorMesh3D\n\nconstructs TensorMesh3D\n\nRequired Input:\n\n   h1::Array - cell-sizes in x1 direction\n   h2::Array - cell-sizes in x2 direction\n   h3::Array - cell-sizes in x3 direction\n\nOptional Input\n   x0::Array - origin (default = zeros(3))\n\n\n\n\n#\n\n\njInv.Mesh.getdEdgeMassMatrix\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getdEdgeMassMatrix(mesh,v)\n\nReturns derivative of edge mass matrix. Matrix is always \nconstructed. Uses pre-constructed edge averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       v::Vector\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}\n\n\n\n\n#\n\n\njInv.Mesh.getdFaceMassMatrix\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getdFaceMassMatrix(Mesh,v)\n\nReturns derivative of face mass matrix. Matrix is always \nconstructed. Uses pre-constructed face averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       v::Vector\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}\n\n\n\n\n#\n\n\njInv.Mesh.getdNodalMassMatrix\n \n \nFunction\n.\n\n\nfunction jInv.Mesh.getdNodalMassMatrix(Mesh,v)\n\nReturns derivative of nodal mass matrix. Matrix is always \nconstructed. Uses pre-constructed nodal averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       v::Vector\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}", 
            "title": "Mesh"
        }, 
        {
            "location": "/Mesh/#jinvmesh", 
            "text": "Currently, the  Mesh  submodule methods and provides operators on regular and tensor meshes but is easily extensible. All meshes are instances of  AbstractMesh .", 
            "title": "jInv.Mesh"
        }, 
        {
            "location": "/Mesh/#list-of-types-and-methods", 
            "text": "#  jInv.Mesh.RegularMesh     Type .  type jInv.Mesh.RegularMesh  : AbstractTensorMesh\n\nRegular mesh in 1D, 2D, and 3D\n\nFields:\n\n    domain::Vector{Float64}  - physical domain [min(x1) max(x1) min(x2) max(x2)]\n    h::Vector{Float64}       - cell size\n    x0::Vector{Float64}      - origin\n    dim::Int                 - dimension of mesh\n    n::Vector{Int64}         - number of cells in each dimension\n    nc::Int                  - total number of cells\n    nf::Vector{Int64}        - number of faces in each dimension\n    ne::Vector{Int64}        - number of edges in each dimension\n\n\n    Persistent Operators:\n\n    Operators should not be accessed directly. They will be built, if needed,\n    when accessing them using specified method. clear!(M) will release all \n    memory.\n\n        Div::SparseMatrixCSC    - divergence (faces -  cell-centers)\n                                  Access via: getDivergenceMatrix(M)\n        Grad::SparseMatrixCSC   - gradient (nodal -  edges)\n                                  Access via: getNodalGradientMatrix(M)\n        Curl::SparseMatrixCSC   - curl (edges -  faces)\n                                  Access via: getCurlMatrix(M)\n        Af::SparseMatrixCSC     - face average (faces -  cell-centers)\n                                  Access via: getFaceAverageMatrix(M)\n        Ae::SparseMatrixCSC     - edge average (edges -  cell-centers)\n                                  Access via: getEdgeAverageMatrix(M)\n        An::SparseMatrixCSC     - nodal average (nodes -  cell-centers)\n                                  Access via: getNodalAverageMatrix(M)\n        V::SparseMatrixCSC      - cell volumes (diagonal matrix)\n                                  Access via: getVolume(M)\n        F::SparseMatrixCSC      - face area (diagonal matrix)\n                                  Access via: getFaceArea(M)\n        L::SparseMatrixCSC      - edge length (diagonal matrix)\n                                  Access via: getLength(M)\n        Vi::SparseMatrixCSC     - inverse cell volumes (diagonal matrix)\n                                  Access via: getVolumeInv(M)\n        Fi::SparseMatrixCSC     - inverse face area (diagonal matrix)\n                                  Access via: getFaceAreaInv(M)\n        Li::SparseMatrixCSC     - inverse edge length (diagonal matrix)\n                                  Access via: getLengthAreaInv(M)\n        nLap::SparseMatrixCSC   - nodal Laplacian\n                                  Access via: getNodalLaplacian(M)\n\nExamples:\nM2D  = getRegularMesh([1.2 2.4 2.2 5.0],[3,4])  \nM3D  = getRegularMesh([1.2 2.4 2.2 5.0 0 1],[3,4,7])  #  jInv.Mesh.TensorMesh3D     Type .  type jInv.Mesh.TensorMesh3D  : AbstractTensorMesh\n\nFields:\n\n    h1::Vector{Float64}     - cell size in x1 direction\n    h2::Vector{Float64}     - cell size in x2 direction\n    h3::Vector{Float64}     - cell size in x3 direction\n    x0::Vector{Float64}     - origin\n    dim::Int                - dimension (dim=3)\n    n::Vector{Int64}        - number of cells in each direction\n    nc::Int                 - nc total number of cells (nc=prod(n))\n    nf::Vector{Int64}       - number of faces\n    ne::Vector{Int64}       - number of edges\n\nPersistent Operators:\n\nOperators should not be accessed directly. They will be built, if needed,\nwhen accessing them using specified method. clear!(M) will release all \nmemory.\n\n    Div::SparseMatrixCSC    - divergence (faces -  cell-centers)\n                              Access via: getDivergenceMatrix(M)\n    Grad::SparseMatrixCSC   - gradient (nodal -  edges)\n                              Access via: getNodalGradientMatrix(M)\n    Curl::SparseMatrixCSC   - curl (edges -  faces)\n                              Access via: getCurlMatrix(M)\n    Af::SparseMatrixCSC     - face average (faces -  cell-centers)\n                              Access via: getFaceAverageMatrix(M)\n    Ae::SparseMatrixCSC     - edge average (edges -  cell-centers)\n                              Access via: getEdgeAverageMatrix(M)\n    An::SparseMatrixCSC     - nodal average (nodes -  cell-centers)\n                              Access via: getNodalAverageMatrix(M)\n    V::SparseMatrixCSC      - cell volumes (diagonal matrix)\n                              Access via: getVolume(M)\n    F::SparseMatrixCSC      - face area (diagonal matrix)\n                              Access via: getFaceArea(M)\n    L::SparseMatrixCSC      - edge length (diagonal matrix)\n                              Access via: getLength(M)\n    Vi::SparseMatrixCSC     - inverse cell volumes (diagonal matrix)\n                              Access via: getVolumeInv(M)\n    Fi::SparseMatrixCSC     - inverse face area (diagonal matrix)\n                              Access via: getFaceAreaInv(M)\n    Li::SparseMatrixCSC     - inverse edge length (diagonal matrix)\n                              Access via: getLengthAreaInv(M)\n    nLap::SparseMatrixCSC   - nodal Laplacian\n                              Access via: getNodalLaplacian(M)\n\nExample: \n\nh1 = rand(4); h2 = rand(6); h3 = rand(5);\nM  = getTensorMesh2D(h1,h2,h3)  #  jInv.Mesh.getEdgeAverageMatrix     Function .  function jInv.Mesh.getEdgeAverageMatrix  Returns Edge-to-CellCenter average matrix from Mesh.Ae. \nMatrix is constructed if Mesh.Ae is empty. \n\nFor 3D Mesh: Ae = [A1 A2 A3]\n\nInput: \n    Mesh::Abstract Mesh  #  jInv.Mesh.getEdgeMassMatrix     Function .  function jInv.Mesh.getEdgeMassMatrix(mesh,sigma)\n\nReturns mass matrix on cell edges, weighted by vector sigma.\nMatrix is always constructed. Uses pre-constructed edge averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       sigma::Vector\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}  #  jInv.Mesh.getFaceAverageMatrix     Function .  function jInv.Mesh.getFaceAverageMatrix  Returns Face-to-CellCenter average matrix from Mesh.Af. \nMatrix is constructed if Mesh.Af is empty. \n\nFor 2D Mesh: Af = [A1 A2]\nFor 3D Mesh: Af = [A1 A2 A3]\n\nInput: \n    Mesh::Abstract Mesh  #  jInv.Mesh.getFaceMassMatrix     Function .  function jInv.Mesh.getFaceMassMatrix(Mesh,sigma)\n\nReturns face mass matrix, weighted by vector sigma. \nMatrix is always constructed. Uses pre-constructed face averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       sigma::Vector\n\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}  #  jInv.Mesh.getInterpolationMatrix     Function .  function jInv.Mesh.getInterpolationMatrix  computes bi/trilinear interpolation matrix P for cell-centered data from Mesh1 to Mesh2. If I1 is a cell-centerd discretization of some function  on Mesh1 then, its interpolant on Mesh2 is given by  I2 = P*I1  Required Input:  M1::AbstractTensorMesh \nM2::AbstractTensorMesh  Example:  In mesh-decoupling, we use different meshes for the inverse solution\nand the different forward problems. \n\nMesh2Mesh = getInterpolationMatrix(Minv,Mfor)  #  jInv.Mesh.getNodalAverageMatrix     Function .  function jInv.Mesh.getNodalAverageMatrix  Returns Nodal-to-CellCenter average matrix from Mesh.An. \nMatrix is constructed if Mesh.An is empty. \n\nInput: \n    Mesh::Abstract Mesh  #  jInv.Mesh.getNodalMassMatrix     Function .  function jInv.Mesh.getNodalMassMatrix(Mesh,sigma)\n\nReturns nodal mass matrix, weighted by vector sigma. \nMatrix is always constructed. Uses pre-constructed nodal averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       sigma::Vector\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}  #  jInv.Mesh.getRegularMesh     Function .  function jInv.Mesh.getRegularMesh\n\nConstructs regular mesh\n\nInput: \n    domain - physical domain rectangular\n    n      - number of cells in each dimension\n\nExamples:\nM2D  = getRegularMesh([1.2 2.4 2.2 5.0],[3,4])  \nM3D  = getRegularMesh([1.2 2.4 2.2 5.0 0 1],[3,4,7])  #  jInv.Mesh.getTensorMesh3D     Function .  function jInv.Mesh.getTensorMesh3D\n\nconstructs TensorMesh3D\n\nRequired Input:\n\n   h1::Array - cell-sizes in x1 direction\n   h2::Array - cell-sizes in x2 direction\n   h3::Array - cell-sizes in x3 direction\n\nOptional Input\n   x0::Array - origin (default = zeros(3))  #  jInv.Mesh.getdEdgeMassMatrix     Function .  function jInv.Mesh.getdEdgeMassMatrix(mesh,v)\n\nReturns derivative of edge mass matrix. Matrix is always \nconstructed. Uses pre-constructed edge averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       v::Vector\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}  #  jInv.Mesh.getdFaceMassMatrix     Function .  function jInv.Mesh.getdFaceMassMatrix(Mesh,v)\n\nReturns derivative of face mass matrix. Matrix is always \nconstructed. Uses pre-constructed face averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       v::Vector\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}  #  jInv.Mesh.getdNodalMassMatrix     Function .  function jInv.Mesh.getdNodalMassMatrix(Mesh,v)\n\nReturns derivative of nodal mass matrix. Matrix is always \nconstructed. Uses pre-constructed nodal averaging\nand cell volume matrices if available.\n\nInput: \n    Mesh::Abstract Mesh\n       v::Vector\n\nOutput:\n    SparseMatrixCSC{Float64,Int64}", 
            "title": "List of types and methods"
        }, 
        {
            "location": "/LinearSolvers/", 
            "text": "jInv.LinearSolvers\n\n\nThe \nLinearSolvers\n submodule provides wrappers iterative and direct solvers for linear systems such as discretized PDEs.\n\n\n\n\nSupported Packages\n\n\nThe module looks for MUMPS, Pardiso, and SpMatVec. \n\n\n\n\nList of types and methods\n\n\n#\n\n\njInv.LinearSolvers.BlockIterativeSolver\n \n \nType\n.\n\n\ntype BlockIterativeSolver\n\n\nFields:\n\n\nIterMethod - iterative method to apply\nPC      - symbol, (:ssor, :jac,...)\nmaxIter - maximum number of iterations\ntol     - tolerance\nAinv    - preconditioner\nout     - flag for output\ndoClear - flag for deleting preconditioner\nnthreads - number of threads for spmatvecs\nsym      - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nisTranspose - if true, transpose(A) is provided to solver, else A is proved to solver\n          default=false, use isTranspose=true for efficiency with caution\n          note that A_mul_B! is slower than Ac_mul_B for SparseMatrixCSC\n\n\n\n\nExample getBlockIterativeSolver()\n\n\n#\n\n\njInv.LinearSolvers.IterativeSolver\n \n \nType\n.\n\n\ntype jInv.LinearSolvers.IterativeSolver \n: AbstractSolver\n\n\nFields:\n\n\nIterMethod - iterative method to apply\nPC      - symbol, (:ssor, :jac,...)\nmaxIter - maximum number of iterations\ntol     - tolerance\nAinv    - preconditioner\nout     - flag for output\ndoClear - flag for deleting preconditioner\nnthreads - number of threads for spmatvecs\nsym      - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nisTranspose - if true, transpose(A) is provided to solver, else A is proved to solver\n          default=false, use isTranspose=true for efficiency with caution\n          note that A_mul_B! is slower than Ac_mul_B for SparseMatrixCSC\n\n\n\n\nExample:\n\n\ngetIterativeSolver(cg)\n\n\n\n\n#\n\n\njInv.LinearSolvers.MUMPSsolver\n \n \nType\n.\n\n\ntype MUMPSsolver\n\n\nFields:\n\n\nAinv    - holds MUMPSfactorization\ndoClear - flag to clear factorization\nooc     - flag for out-of-core option\nsym     - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nnFac    - number of factorizations performed\nfacTime - cumulative time for factorizations\nnSolve  - number of solves\nsolveTime - cumnulative time for solves\n\n\n\n\nExample: \n\n\nAinv = getMUMPSsolver()\n\n\n\n\n#\n\n\njInv.LinearSolvers.jInvPardisoSolver\n \n \nType\n.\n\n\ntype jInvPardisoSolver\n\n\nFields:\n\n\nAinv    - holds PardisoFactorization\ndoClear - flag to clear factorization\nooc     - flag for out-of-core option\nsym     - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nnFac    - number of factorizations performed\nfacTime - cumulative time for factorizations\nnSolve  - number of solves\nsolveTime - cumulative time for solves\n\n\n\n\nExample: \n\n\nAinv = getjInvPardisoSolver()\n\n\n\n\n#\n\n\njInv.LinearSolvers.getBlockIterativeSolver\n \n \nFunction\n.\n\n\nfunction jInv.LinearSolvers.getBlockIterativeSolver\n\n\nconstructs BlockIterativeSolver\n\n\nRequired Input:\n\n\nIterMethod::Function   - function handle for linear solvers \n    Inputs are: (A,B,M), A is matrix, B are right hand sides, M is preconditioner\n        Examples: \n              IterMethod = blockCG\n              IterMethod(A,B;M=M,tol=1e-1,maxIter=10,out=-1) =\n                              blockBiCGSTB(A,b,M1=M,tol=tol,maxIter=maxIter,out=out)\n        The keyword arguments of IterMethod for blockBiCGSTB\n        will be initialized with the fields in the IterativeSolver type.\n    Outputs are: (X,flag,err,iter), X are approximate solutions\n\n\n\n\nOptional Inputs:\n\n\nPC::Symbol     - specifies preconditioner, default:ssor\nmaxIter        - maximum number of iterations, default:500\ntol            - tolerance on relative residual, default=1e-5\nAinv           - preconditioner, default=identity\nout            - flag for output, default=-1 (no output)\ndoClear        - flag for clearing the preconditioner, default=true\nnthreads       - number of threads to use for matvecs (requires ParSpMatVec.jl), default=4\nsym            - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nisTranspose    - if true, transpose(A) is provided to solver, else A is proved to solver\n                  default=false, use isTranspose=true for efficiency with caution\n                  note that A_mul_B! is slower than Ac_mul_B for SparseMatrixCSC\n\n\n\n\n#\n\n\njInv.LinearSolvers.getIterativeSolver\n \n \nFunction\n.\n\n\nfunction jInv.LinearSolvers.getIterativeSolver\n\n\nconstructs IterativeSolver\n\n\nRequired Input:\n\n\nIterMethod::Function   - function handle for linear solvers \n    Inputs are: (A,b,M), A is matrix, b is right hand side, M is preconditioner\n        Examples: IterMethod = KrylovMethods.cg   #KrylovMethods.cg already has required API\n              IterMethod(A,b;M=M,tol=1e-1,maxIter=10,out=-1) =\n                              bicgstb(A,b,M1=M,tol=tol,maxIter=maxIter,out=out)\n              IterMethod(A,b;M=M,tol=1e-1,maxIter=10,out=-1)  = \n                              gmres(A,b,5,M1=M,tol=tol,maxIter=maxIter,out=out)\n        The keyword arguments of IterMethod for bicgstb and gmres\n        will be initialized with the fields in the IterativeSolver type.\n    Outputs are: (x,flag,err,iter), x is approximate solution\n\n\n\n\nOptional Inputs:\n\n\nPC::Symbol     - specifies preconditioner, default:ssor\nmaxIter        - maximum number of iterations, default:500\ntol            - tolerance on relative residual, default=1e-5\nAinv           - preconditioner, default=identity\nout            - flag for output, default=-1 (no output)\ndoClear        - flag for clearing the preconditioner, default=true\nnthreads       - number of threads to use for matvecs (requires ParSpMatVec.jl), default=4\nsym            - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nisTranspose    - if true, transpose(A) is provided to solver, else A is proved to solver\n                  default=false, use isTranspose=true for efficiency with caution\n                  note that A_mul_B! is slower than Ac_mul_B for SparseMatrixCSC", 
            "title": "LinearSolvers"
        }, 
        {
            "location": "/LinearSolvers/#jinvlinearsolvers", 
            "text": "The  LinearSolvers  submodule provides wrappers iterative and direct solvers for linear systems such as discretized PDEs.", 
            "title": "jInv.LinearSolvers"
        }, 
        {
            "location": "/LinearSolvers/#supported-packages", 
            "text": "The module looks for MUMPS, Pardiso, and SpMatVec.", 
            "title": "Supported Packages"
        }, 
        {
            "location": "/LinearSolvers/#list-of-types-and-methods", 
            "text": "#  jInv.LinearSolvers.BlockIterativeSolver     Type .  type BlockIterativeSolver  Fields:  IterMethod - iterative method to apply\nPC      - symbol, (:ssor, :jac,...)\nmaxIter - maximum number of iterations\ntol     - tolerance\nAinv    - preconditioner\nout     - flag for output\ndoClear - flag for deleting preconditioner\nnthreads - number of threads for spmatvecs\nsym      - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nisTranspose - if true, transpose(A) is provided to solver, else A is proved to solver\n          default=false, use isTranspose=true for efficiency with caution\n          note that A_mul_B! is slower than Ac_mul_B for SparseMatrixCSC  Example getBlockIterativeSolver()  #  jInv.LinearSolvers.IterativeSolver     Type .  type jInv.LinearSolvers.IterativeSolver  : AbstractSolver  Fields:  IterMethod - iterative method to apply\nPC      - symbol, (:ssor, :jac,...)\nmaxIter - maximum number of iterations\ntol     - tolerance\nAinv    - preconditioner\nout     - flag for output\ndoClear - flag for deleting preconditioner\nnthreads - number of threads for spmatvecs\nsym      - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nisTranspose - if true, transpose(A) is provided to solver, else A is proved to solver\n          default=false, use isTranspose=true for efficiency with caution\n          note that A_mul_B! is slower than Ac_mul_B for SparseMatrixCSC  Example:  getIterativeSolver(cg)  #  jInv.LinearSolvers.MUMPSsolver     Type .  type MUMPSsolver  Fields:  Ainv    - holds MUMPSfactorization\ndoClear - flag to clear factorization\nooc     - flag for out-of-core option\nsym     - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nnFac    - number of factorizations performed\nfacTime - cumulative time for factorizations\nnSolve  - number of solves\nsolveTime - cumnulative time for solves  Example:   Ainv = getMUMPSsolver()  #  jInv.LinearSolvers.jInvPardisoSolver     Type .  type jInvPardisoSolver  Fields:  Ainv    - holds PardisoFactorization\ndoClear - flag to clear factorization\nooc     - flag for out-of-core option\nsym     - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nnFac    - number of factorizations performed\nfacTime - cumulative time for factorizations\nnSolve  - number of solves\nsolveTime - cumulative time for solves  Example:   Ainv = getjInvPardisoSolver()  #  jInv.LinearSolvers.getBlockIterativeSolver     Function .  function jInv.LinearSolvers.getBlockIterativeSolver  constructs BlockIterativeSolver  Required Input:  IterMethod::Function   - function handle for linear solvers \n    Inputs are: (A,B,M), A is matrix, B are right hand sides, M is preconditioner\n        Examples: \n              IterMethod = blockCG\n              IterMethod(A,B;M=M,tol=1e-1,maxIter=10,out=-1) =\n                              blockBiCGSTB(A,b,M1=M,tol=tol,maxIter=maxIter,out=out)\n        The keyword arguments of IterMethod for blockBiCGSTB\n        will be initialized with the fields in the IterativeSolver type.\n    Outputs are: (X,flag,err,iter), X are approximate solutions  Optional Inputs:  PC::Symbol     - specifies preconditioner, default:ssor\nmaxIter        - maximum number of iterations, default:500\ntol            - tolerance on relative residual, default=1e-5\nAinv           - preconditioner, default=identity\nout            - flag for output, default=-1 (no output)\ndoClear        - flag for clearing the preconditioner, default=true\nnthreads       - number of threads to use for matvecs (requires ParSpMatVec.jl), default=4\nsym            - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nisTranspose    - if true, transpose(A) is provided to solver, else A is proved to solver\n                  default=false, use isTranspose=true for efficiency with caution\n                  note that A_mul_B! is slower than Ac_mul_B for SparseMatrixCSC  #  jInv.LinearSolvers.getIterativeSolver     Function .  function jInv.LinearSolvers.getIterativeSolver  constructs IterativeSolver  Required Input:  IterMethod::Function   - function handle for linear solvers \n    Inputs are: (A,b,M), A is matrix, b is right hand side, M is preconditioner\n        Examples: IterMethod = KrylovMethods.cg   #KrylovMethods.cg already has required API\n              IterMethod(A,b;M=M,tol=1e-1,maxIter=10,out=-1) =\n                              bicgstb(A,b,M1=M,tol=tol,maxIter=maxIter,out=out)\n              IterMethod(A,b;M=M,tol=1e-1,maxIter=10,out=-1)  = \n                              gmres(A,b,5,M1=M,tol=tol,maxIter=maxIter,out=out)\n        The keyword arguments of IterMethod for bicgstb and gmres\n        will be initialized with the fields in the IterativeSolver type.\n    Outputs are: (x,flag,err,iter), x is approximate solution  Optional Inputs:  PC::Symbol     - specifies preconditioner, default:ssor\nmaxIter        - maximum number of iterations, default:500\ntol            - tolerance on relative residual, default=1e-5\nAinv           - preconditioner, default=identity\nout            - flag for output, default=-1 (no output)\ndoClear        - flag for clearing the preconditioner, default=true\nnthreads       - number of threads to use for matvecs (requires ParSpMatVec.jl), default=4\nsym            - 0=unsymmetric, 1=symm. pos def, 2=general symmetric\nisTranspose    - if true, transpose(A) is provided to solver, else A is proved to solver\n                  default=false, use isTranspose=true for efficiency with caution\n                  note that A_mul_B! is slower than Ac_mul_B for SparseMatrixCSC", 
            "title": "List of types and methods"
        }, 
        {
            "location": "/InverseSolve/", 
            "text": "jInv.InverseSolve\n\n\nThe \nInverseSolve\n submodule contains misfit functions, regularizers, optimization and other tools for solving PDE parameter estimation problems. \n\n\n#\n\n\njInv.InverseSolve.GlobalToLocal\n \n \nType\n.\n\n\ntype jInv.InverseSolve.GlobalToLocal\n\n\nMaps global model to local model\n\n\nsigLocal = PForInv*sigGlobal + sigmaBackground\n\n\nFields:     PForInv::SparseMatrixCSC - linear operator between inverse mesh and                                forward mesh, e.g., linear interpolation matrix                                and projection on active set.     sigmaBackground::Vector  - background model\n\n\nConstructors:     getGlobalToLocal(P::SparseMatrixCSC)  getGlobalToLocal(P::SparseMatrixCSC,sigmaBack::Vector)\n\n\nExample:    Mesh2Mesh = getInterpolationMatrix(Minv,Mfwd)   # Minv and Mfwd have different resolutions  sigmaBack = 1.2*ones(Minv.nc)                   # put background conductivity   gloc      = getGlobalToLocal(Mesh2Mesh,sigmaBack)\n\n\nsigLocal     = gloc.PForInv' * sigGlobal + gloc.sigmaBack\n# this call is equivalent, but needed in case the Mesh2Mesh matrix is compressed\nsigLocalFast = interpGlobalToLocal(sigGlobal,gloc.PForInv,gloc.sigmaBack)\n\n\n\n\n#\n\n\njInv.InverseSolve.InverseParam\n \n \nType\n.\n\n\ntype jInv.InverseSolve.InverseParam\n\nType storing parameters for Inversion. \n\nFields:\n    Minv::AbstractMesh\n    modelfun::Function    - model function (evaluated by main worker), see models.jl\n    regularizer::Function - regularizer, see regularizer.jl\n    alpha::Real           - regularization parameter\n    mref::Array           - reference model\n    boundsLow::Vector     - lower bounds for model\n    boundsHigh::Vector    - upper bounds for model\n    maxStep::Real         - maximum step in optimization\n    pcgMaxIter::Int       - maximum number of PCG iterations\n    pcgTol::Real          - tolerance for PCG\n    minUpdate::Real       - stopping criteria\n    maxIter::Int          - maximum number of iterations\n    HesPrec               - A preconditioner for the Hessian.\nConstructor:\n    getInverseParam\n\nExample: \n    Minv = getRegularMesh(domain,n)\n    modelfun = expMod\n    regularizer(m,mref,Minv) = wdiffusionReg(m,mref,Minv)\n    alpha   = 1e-3\n    mref    = zeros(Minv.nc)\n    pInv = getInverseParam(Minv,modelfun,regularizer,alpha,mref)\n\n\n\n\n#\n\n\njInv.InverseSolve.MisfitParam\n \n \nType\n.\n\n\ntype jInv.InverseSolve.MisfitParam\n\n\nType storing information about one term in the misfit\n\n\nF(m) = sum_i^n phi_i(pFor(model(m)),dobs,Wd)\n\n\nFields:\n\n\npFor::ForwardProbType  - forward problem\nWd                     - inverse standard deviation\ndobs                   - observed data\nmisfit::Function       - misfit function\nmodelfun::Function     - model function (evaluated locally)\ngloc                   - mapping from inverse to forward mesh (including active cells projection).\n\n\n\n\nConstructors:\n\n\ngetMisfitParam(pFor,Wd,dobs,misfit,model,gloc=getGlobalToLocal(1.0)) \n\n\ngetMisfitParam(pForRFs::Array{RemoteRef{Channel{Any}}}, Wd::Array, dobs::Array, misfit::Function,                           Iact,sigmaBack::Vector,                             Mesh2MeshRFs::Union{Array{RemoteRef{Channel{Any}}},Array{Float64}}=ones(length(pForRFs)),                           modelfun::Function=identityMod,fname=\"\")\n\n\n#\n\n\njInv.InverseSolve.HuberFun\n \n \nFunction\n.\n\n\nmis,dmis,d2mis = HuberFun(dc,dobs,Wd,C)\n\nComputes misfit via\n\n    misfit(dc,dobs) = sqrt(abs(Wd*res).^2 + eps)\n\nInput:\n    dc::Array   -  simulated data\n    dobs::Array -  measured data\n    Wd::Array   -  diagional weighting\n    eps         -  conditioning parameter (default=1e-3)\n\nOutput:\n    mis::Real   -  misfit\n    dmis        -  gradient\n    d2mis       -  diagonal of Hessian\n\n\n\n\n#\n\n\njInv.InverseSolve.SSDFun\n \n \nFunction\n.\n\n\nFor complex data misfit is computed as 0.5*|real(dc)-(dobs)|_Wd^2 +  0.5*|complex(dc)-complex(dobs)|_W^2\n\n\n\n\nmis,dmis,d2mis = SSDFun(dc,dobs,Wd)\n\nInput:\n\n    dc::Array   -  simulated data\n    dobs::Array -  measured data\n    Wd::Array   -  diagonal weighting\n\nOutput:\n\n    mis::Real   -  misfit, 0.5*|dc-dobs|_Wd^2\n    dmis        -  gradient\n    d2mis       -  diagonal of Hessian\n\n\n\n\n#\n\n\njInv.InverseSolve.boundMod\n \n \nFunction\n.\n\n\nsigma,dsigma = boundMod(m;boundLow=0.0,boundHigh=1.0)\n\nmaps model parameter to conductivity via\n\n    sigma = 0.5*(boundHigh-boundLow) * (tanh(m)+1.0 ) + boundLow\n\n\n\n\n#\n\n\njInv.InverseSolve.computeMisfit\n \n \nFunction\n.\n\n\nDc,F,dF,d2F = computeMisfit(...)\n\nComputes misfit for PDE parameter estimation problem.\n\ncomputeMisfit has several options.\n\n\n\n\n#\n\n\njInv.InverseSolve.diffusionReg\n \n \nFunction\n.\n\n\nRc,dR,d2R = diffusionReg(m,mref,M,Iact=1.0)\n\nCompute diffusion regularizer\n    0.5*||GRAD*(m-mref)||_V^2\n\nInput:\n    m     - model\n    mref  - reference model\n    M     - Mesh\n    Iact  - projector on active cells\n\nOutput\n    Rc    - value of regularizer\n    dR    - gradient w.r.t. m\n    d2R   - Hessian\n\n\n\n\n#\n\n\njInv.InverseSolve.expMod\n \n \nFunction\n.\n\n\nsigma,dsigma = expMod(model)\n\nmaps model parameter to conductivity via\n\nsigma(m) = exp(m)\n\n\n\n\n#\n\n\njInv.InverseSolve.fMod\n \n \nFunction\n.\n\n\nsigma,dsigma = fMod(model;f::Function=identity,df::Function=m-\nspeye(length(m)))\n\nmaps model parameter to conductivity via\n\nsigma(m) = f(m) and dsigma(m) = sdiag(df(m))\n\n\n\n\n#\n\n\njInv.InverseSolve.getInverseParam\n \n \nFunction\n.\n\n\nfunction jInv.InverseSolve.getInverseParam(...)\n\n\nConstructs an InverseParam\n\n\nRequired Input:\n\n\nMinv::AbstractMesh    - mesh of model\nmodFun::Function      - model\nregularizer::Function - regularizer, see regularizer.jl\nalpha::Real           - regularization parameter\nmref                  - reference model\nboundsLow::Vector     - lower bounds for model\nboundsHigh::Vector    - upper bounds for model\n\n\n\n\nOptional Inputs:\n\n\nmaxStep::Real=1.0     - maximum step in optimization\npcgMaxIter::Int=10    - maximum number of PCG iterations\npcgTol::Real          - tolerance for PCG\nminUpdate::Real=1e-4  - stopping criteria\nmaxIter::Int=10       - maximum number of iterations\n\n\n\n\n#\n\n\njInv.InverseSolve.getMisfitParam\n \n \nFunction\n.\n\n\nfunction jInv.InverseSolve.getMisfitParam\n\n\nRequired Input: \n\n\nInput for a call:   getMisfitParam(pFor,Wd,dobs,misfit,model,gloc=getGlobalToLocal(1.0)) \n\n\npFor::ForwardProbType  - forward problem\nWd                     - inverse standard deviation of data\ndobs                   - observed data\nmisfit::Function       - Misfit function \nmodelfun::Function     - model function. If all misfits have same model function, \n                         put modelfun in inverseParam and identityMod here for efficiency.\ngloc                   - mapping from inverse to forward mesh (default: identity). See globalToLocal.jl\n\n\n\n\nInput for a call:   getMisfitParam(pForRFs::Array{RemoteRef{Channel{Any}}}, Wd::Array, dobs::Array, misfit::Function,                           Iact,sigmaBack::Vector, Mesh2MeshRFs::Union{Array{RemoteRef{Channel{Any}}},Array{Float64}}=ones(length(pForRFs)),                           modelfun::Function=identityMod,fname=\"\")\n\n\npForRFs::Array{RemoteRef{Channel{Any}}}                 - Array of remote references for forward problem parameters on each worker.\nWd::Array                               - Array of inverse standard deviation for the data on each worker.\ndobs::Array                             - Array of observed data for each worker.\nmisfit::Function                            - Misfit function \nIact                                        - Projector to active cells.\nsigmaBack::Vector                           - Background model (\nfrozen\n cells).                    \nMesh2MeshRFs::Union{Array{RemoteRef{Channel{Any}}},Array{Float64}}  - mapping from inverse to forward mesh (default: identity) \nmodelfun::Function=identityMod                      - model function. If all misfits have same model function, \n                                      put modelfun in inverseParam and identityMod here for efficiency.\nfname=\n                                - (optional)\n\n\n\n\n#\n\n\njInv.InverseSolve.iteratedTikhonov\n \n \nFunction\n.\n\n\nmc,DC = iteratedTikhonov(mc,pInv::InverseParam,pMis,nAlpha,alphaFac,\n                        targetMisfit;indCredit=[],dumpResults::Function=dummy)\n\nPerform (Projected) Gauss-NewtonCG using iterated Tikhonov procedure to decrease\nregularization parameter and update reference model after fixed number of GN iterations\nset in pInv.\n\nInput:\n       mc::Vector         - Initial guess for model\n       pInv::InverseParam - parameter for inversion\n       pMis               - misfit terms\n       nAlpha             - maximum number of allowed regularization parameter (alpha) values\n       alphaFac           - alpha decrease factor. alpha_(i+1) = alpha_i/alphaFac\n       targetMisfit       - Termination criterion. iteratedTikhonov will exit \n                             -when data misfit \n targetMisfit\n       indCredit          - indices of forward problems to work on\n       dumpResults        - A function pointer for saving the results throughout the iterations.\n                             - We assume that dumpResults is dumpResults(mc,Dc,iter,pInv,pMis), \n                             - where mc is the recovered model, Dc is the predicted data. \n                             - If dumpResults is not given, nothing is done (dummy() is called).\n\nOutput:\n       mc                 - final model\n       Dc                 - final computed data\n       tikhonovFlag       - Data misfit convergence flag\n       hist               - Iteration history. This is a vector. Each entry is\n                             - a structure containing the projGNCG history for each\n                             - alpha value.\n\n\n\n\n#\n\n\njInv.InverseSolve.logBarrier\n \n \nFunction\n.\n\n\nRc,dR,d2R = logBarrier(m::Vector, z::Vector, M::AbstractMesh,low::Vector,high::Vector, epsilon)\n\nComputes logBarrier regularizer\n\nR = -log(1 - ((m-high)/epsilon).^2) if high-epsilon \n  m \n high\n                0                   if low+epsilon  \n= m \n= high-epsilon\n    -log(1 - ((m-low)/epsilon).^2)  if low          \n  m \n low+epsilon\n\nInput:\n    m       - model\n    z       - not being used. Here for compatibility.\n    M       - Mesh. not being used. Here for compatibility.\n    low     - low bound for each coordinate.\n    high    - high bound for each coordinate.\n    epsilon - layer width of the barier. \n\nOutput\n    g    - value of regularizer\n    dg    - gradient w.r.t. m\n    d2g   - Hessian (diagonal matrix). Second derivative is not continous.\n\n\n\n\n#\n\n\njInv.InverseSolve.logBarrierSquared\n \n \nFunction\n.\n\n\nRc,dR,d2R = logBarrierSquared(m::Vector, z::Vector, M::AbstractMesh,low::Vector,high::Vector, epsilon)\n\nComputes logBarrier regularizer\n\nR = (log(1 - ((m-high)/epsilon).^2))^2 if high-epsilon \n  m \n high\n                0                      if low+epsilon  \n= m \n= high-epsilon\n    (log(1 - ((m-low)/epsilon).^2))^2  if low          \n  m \n low+epsilon\n\nInput:\n    m       - model\n    z       - not being used. Here for compatibility.\n    M       - Mesh. not being used. Here for compatibility.\n    low     - low bound for each coordinate.\n    high    - high bound for each coordinate.\n    epsilon - layer width of the barier. \n\nOutput\n    g    - value of regularizer\n    dg    - gradient w.r.t. m\n    d2g   - Gauss Newton Hessian approximation (diagonal matrix). Second derivative approx is continous.\n\n\n\n\n#\n\n\njInv.InverseSolve.projGNCG\n \n \nFunction\n.\n\n\nmc,Dc,outerFlag = projGNCG(mc,pInv::InverseParam,pMis, indFor = [], dumpResults::Function = dummy)\n\n(Projected) Gauss-NewtonCG\n\nInput:\n\n    mc::Vector          - intial guess for model\n    pInv::InverseParam  - parameter for inversion\n    pMis                - misfit terms\n    indCredit           - indices of forward problems to work on\n    dumpResults         - A function pointer for saving the results throughout the iterations.\n                        - We assume that dumpResults is dumpResults(mc,Dc,iter,pInv,pMis), \n                        - where mc is the recovered model, Dc is the predicted data. \n                        - If dumpResults is not given, nothing is done (dummy() is called).\n    out::Int            - flag for output (-1: no output, 1: final status, 2: residual norm at each iteration)\n\nOutput:\n    mc                  - final model\n    Dc                  - data\n    outerFlag           - flag for convergence\n    His                 - iteration history\n\n\n\n\n#\n\n\njInv.InverseSolve.projPCG\n \n \nFunction\n.\n\n\ndm = projPCG(H,g,Active,Precond,cgTol,maxIter)\n\nProjected Preconditioned Conjugate Gradient method for solving\n\n    H*dm = g    subject to    dm[!Active] == 0 \n\nInput:\n\n    H::Function       -  computes action of Hessian\n    g::Vector         -  right hand side\n    Active            -  describes active cells\n    Precond::Function - preconditioner\n    cgTol             - tolerance\n    maxIter             - maximum number of iterations\n\n\n\n\n#\n\n\njInv.InverseSolve.smallnessReg\n \n \nFunction\n.\n\n\nRc,dR,d2R = smallnessReg(m,mref,M,Iact=1.0)\n\nCompute smallness regularizer (L2 difference to reference model)\n\n    R(m) = 0.5*||m-mref||_V^2\n\nInput:\n    m     - model\n    mref  - reference model\n    M     - Mesh\n\nOutput\n    Rc    - value of regularizer\n    dR    - gradient w.r.t. m\n    d2R   - Hessian\n\n\n\n\n#\n\n\njInv.InverseSolve.wTVReg\n \n \nFunction\n.\n\n\nRc,dR,d2R = wTVReg(m,mref,M,Iact,C=[])\n\nCompute weighted total variation regularizer\n\nInput:\n    m     - model\n    mref  - reference model\n    M     - Mesh\n    Iact  - projector on active cells\n    C     - anisotropy parameters (default: [1 1 1])\n    eps   - conditioning parameter for TV norm (default: 1e-3)\n\nOutput\n    Rc    - value of regularizer\n    dR    - gradient w.r.t. m\n    d2R   - Hessian\n\n\n\n\n#\n\n\njInv.InverseSolve.wdiffusionRegNodal\n \n \nFunction\n.\n\n\nRc,dR,d2R = wdiffusionRegNodal(m::Vector, mref::Vector, M::AbstractMesh; Iact=1.0, C=[])\n\nComputes weighted diffusion regularizer for nodal model\n\nInput:\n    m     - model\n    mref  - reference model\n    M     - Mesh\n    Iact  - projector on active cells\n    C     - optional parameters\n\nOutput\n    Rc    - value of regularizer\n    dR    - gradient w.r.t. m\n    d2R   - Hessian", 
            "title": "InverseSolve"
        }, 
        {
            "location": "/InverseSolve/#jinvinversesolve", 
            "text": "The  InverseSolve  submodule contains misfit functions, regularizers, optimization and other tools for solving PDE parameter estimation problems.   #  jInv.InverseSolve.GlobalToLocal     Type .  type jInv.InverseSolve.GlobalToLocal  Maps global model to local model  sigLocal = PForInv*sigGlobal + sigmaBackground  Fields:     PForInv::SparseMatrixCSC - linear operator between inverse mesh and                                forward mesh, e.g., linear interpolation matrix                                and projection on active set.     sigmaBackground::Vector  - background model  Constructors:     getGlobalToLocal(P::SparseMatrixCSC)  getGlobalToLocal(P::SparseMatrixCSC,sigmaBack::Vector)  Example:    Mesh2Mesh = getInterpolationMatrix(Minv,Mfwd)   # Minv and Mfwd have different resolutions  sigmaBack = 1.2*ones(Minv.nc)                   # put background conductivity   gloc      = getGlobalToLocal(Mesh2Mesh,sigmaBack)  sigLocal     = gloc.PForInv' * sigGlobal + gloc.sigmaBack\n# this call is equivalent, but needed in case the Mesh2Mesh matrix is compressed\nsigLocalFast = interpGlobalToLocal(sigGlobal,gloc.PForInv,gloc.sigmaBack)  #  jInv.InverseSolve.InverseParam     Type .  type jInv.InverseSolve.InverseParam\n\nType storing parameters for Inversion. \n\nFields:\n    Minv::AbstractMesh\n    modelfun::Function    - model function (evaluated by main worker), see models.jl\n    regularizer::Function - regularizer, see regularizer.jl\n    alpha::Real           - regularization parameter\n    mref::Array           - reference model\n    boundsLow::Vector     - lower bounds for model\n    boundsHigh::Vector    - upper bounds for model\n    maxStep::Real         - maximum step in optimization\n    pcgMaxIter::Int       - maximum number of PCG iterations\n    pcgTol::Real          - tolerance for PCG\n    minUpdate::Real       - stopping criteria\n    maxIter::Int          - maximum number of iterations\n    HesPrec               - A preconditioner for the Hessian.\nConstructor:\n    getInverseParam\n\nExample: \n    Minv = getRegularMesh(domain,n)\n    modelfun = expMod\n    regularizer(m,mref,Minv) = wdiffusionReg(m,mref,Minv)\n    alpha   = 1e-3\n    mref    = zeros(Minv.nc)\n    pInv = getInverseParam(Minv,modelfun,regularizer,alpha,mref)  #  jInv.InverseSolve.MisfitParam     Type .  type jInv.InverseSolve.MisfitParam  Type storing information about one term in the misfit  F(m) = sum_i^n phi_i(pFor(model(m)),dobs,Wd)  Fields:  pFor::ForwardProbType  - forward problem\nWd                     - inverse standard deviation\ndobs                   - observed data\nmisfit::Function       - misfit function\nmodelfun::Function     - model function (evaluated locally)\ngloc                   - mapping from inverse to forward mesh (including active cells projection).  Constructors:  getMisfitParam(pFor,Wd,dobs,misfit,model,gloc=getGlobalToLocal(1.0))   getMisfitParam(pForRFs::Array{RemoteRef{Channel{Any}}}, Wd::Array, dobs::Array, misfit::Function,                           Iact,sigmaBack::Vector,                             Mesh2MeshRFs::Union{Array{RemoteRef{Channel{Any}}},Array{Float64}}=ones(length(pForRFs)),                           modelfun::Function=identityMod,fname=\"\")  #  jInv.InverseSolve.HuberFun     Function .  mis,dmis,d2mis = HuberFun(dc,dobs,Wd,C)\n\nComputes misfit via\n\n    misfit(dc,dobs) = sqrt(abs(Wd*res).^2 + eps)\n\nInput:\n    dc::Array   -  simulated data\n    dobs::Array -  measured data\n    Wd::Array   -  diagional weighting\n    eps         -  conditioning parameter (default=1e-3)\n\nOutput:\n    mis::Real   -  misfit\n    dmis        -  gradient\n    d2mis       -  diagonal of Hessian  #  jInv.InverseSolve.SSDFun     Function .  For complex data misfit is computed as 0.5*|real(dc)-(dobs)|_Wd^2 +  0.5*|complex(dc)-complex(dobs)|_W^2  mis,dmis,d2mis = SSDFun(dc,dobs,Wd)\n\nInput:\n\n    dc::Array   -  simulated data\n    dobs::Array -  measured data\n    Wd::Array   -  diagonal weighting\n\nOutput:\n\n    mis::Real   -  misfit, 0.5*|dc-dobs|_Wd^2\n    dmis        -  gradient\n    d2mis       -  diagonal of Hessian  #  jInv.InverseSolve.boundMod     Function .  sigma,dsigma = boundMod(m;boundLow=0.0,boundHigh=1.0)\n\nmaps model parameter to conductivity via\n\n    sigma = 0.5*(boundHigh-boundLow) * (tanh(m)+1.0 ) + boundLow  #  jInv.InverseSolve.computeMisfit     Function .  Dc,F,dF,d2F = computeMisfit(...)\n\nComputes misfit for PDE parameter estimation problem.\n\ncomputeMisfit has several options.  #  jInv.InverseSolve.diffusionReg     Function .  Rc,dR,d2R = diffusionReg(m,mref,M,Iact=1.0)\n\nCompute diffusion regularizer\n    0.5*||GRAD*(m-mref)||_V^2\n\nInput:\n    m     - model\n    mref  - reference model\n    M     - Mesh\n    Iact  - projector on active cells\n\nOutput\n    Rc    - value of regularizer\n    dR    - gradient w.r.t. m\n    d2R   - Hessian  #  jInv.InverseSolve.expMod     Function .  sigma,dsigma = expMod(model)\n\nmaps model parameter to conductivity via\n\nsigma(m) = exp(m)  #  jInv.InverseSolve.fMod     Function .  sigma,dsigma = fMod(model;f::Function=identity,df::Function=m- speye(length(m)))\n\nmaps model parameter to conductivity via\n\nsigma(m) = f(m) and dsigma(m) = sdiag(df(m))  #  jInv.InverseSolve.getInverseParam     Function .  function jInv.InverseSolve.getInverseParam(...)  Constructs an InverseParam  Required Input:  Minv::AbstractMesh    - mesh of model\nmodFun::Function      - model\nregularizer::Function - regularizer, see regularizer.jl\nalpha::Real           - regularization parameter\nmref                  - reference model\nboundsLow::Vector     - lower bounds for model\nboundsHigh::Vector    - upper bounds for model  Optional Inputs:  maxStep::Real=1.0     - maximum step in optimization\npcgMaxIter::Int=10    - maximum number of PCG iterations\npcgTol::Real          - tolerance for PCG\nminUpdate::Real=1e-4  - stopping criteria\nmaxIter::Int=10       - maximum number of iterations  #  jInv.InverseSolve.getMisfitParam     Function .  function jInv.InverseSolve.getMisfitParam  Required Input:   Input for a call:   getMisfitParam(pFor,Wd,dobs,misfit,model,gloc=getGlobalToLocal(1.0))   pFor::ForwardProbType  - forward problem\nWd                     - inverse standard deviation of data\ndobs                   - observed data\nmisfit::Function       - Misfit function \nmodelfun::Function     - model function. If all misfits have same model function, \n                         put modelfun in inverseParam and identityMod here for efficiency.\ngloc                   - mapping from inverse to forward mesh (default: identity). See globalToLocal.jl  Input for a call:   getMisfitParam(pForRFs::Array{RemoteRef{Channel{Any}}}, Wd::Array, dobs::Array, misfit::Function,                           Iact,sigmaBack::Vector, Mesh2MeshRFs::Union{Array{RemoteRef{Channel{Any}}},Array{Float64}}=ones(length(pForRFs)),                           modelfun::Function=identityMod,fname=\"\")  pForRFs::Array{RemoteRef{Channel{Any}}}                 - Array of remote references for forward problem parameters on each worker.\nWd::Array                               - Array of inverse standard deviation for the data on each worker.\ndobs::Array                             - Array of observed data for each worker.\nmisfit::Function                            - Misfit function \nIact                                        - Projector to active cells.\nsigmaBack::Vector                           - Background model ( frozen  cells).                    \nMesh2MeshRFs::Union{Array{RemoteRef{Channel{Any}}},Array{Float64}}  - mapping from inverse to forward mesh (default: identity) \nmodelfun::Function=identityMod                      - model function. If all misfits have same model function, \n                                      put modelfun in inverseParam and identityMod here for efficiency.\nfname=                                 - (optional)  #  jInv.InverseSolve.iteratedTikhonov     Function .  mc,DC = iteratedTikhonov(mc,pInv::InverseParam,pMis,nAlpha,alphaFac,\n                        targetMisfit;indCredit=[],dumpResults::Function=dummy)\n\nPerform (Projected) Gauss-NewtonCG using iterated Tikhonov procedure to decrease\nregularization parameter and update reference model after fixed number of GN iterations\nset in pInv.\n\nInput:\n       mc::Vector         - Initial guess for model\n       pInv::InverseParam - parameter for inversion\n       pMis               - misfit terms\n       nAlpha             - maximum number of allowed regularization parameter (alpha) values\n       alphaFac           - alpha decrease factor. alpha_(i+1) = alpha_i/alphaFac\n       targetMisfit       - Termination criterion. iteratedTikhonov will exit \n                             -when data misfit   targetMisfit\n       indCredit          - indices of forward problems to work on\n       dumpResults        - A function pointer for saving the results throughout the iterations.\n                             - We assume that dumpResults is dumpResults(mc,Dc,iter,pInv,pMis), \n                             - where mc is the recovered model, Dc is the predicted data. \n                             - If dumpResults is not given, nothing is done (dummy() is called).\n\nOutput:\n       mc                 - final model\n       Dc                 - final computed data\n       tikhonovFlag       - Data misfit convergence flag\n       hist               - Iteration history. This is a vector. Each entry is\n                             - a structure containing the projGNCG history for each\n                             - alpha value.  #  jInv.InverseSolve.logBarrier     Function .  Rc,dR,d2R = logBarrier(m::Vector, z::Vector, M::AbstractMesh,low::Vector,high::Vector, epsilon)\n\nComputes logBarrier regularizer\n\nR = -log(1 - ((m-high)/epsilon).^2) if high-epsilon    m   high\n                0                   if low+epsilon   = m  = high-epsilon\n    -log(1 - ((m-low)/epsilon).^2)  if low             m   low+epsilon\n\nInput:\n    m       - model\n    z       - not being used. Here for compatibility.\n    M       - Mesh. not being used. Here for compatibility.\n    low     - low bound for each coordinate.\n    high    - high bound for each coordinate.\n    epsilon - layer width of the barier. \n\nOutput\n    g    - value of regularizer\n    dg    - gradient w.r.t. m\n    d2g   - Hessian (diagonal matrix). Second derivative is not continous.  #  jInv.InverseSolve.logBarrierSquared     Function .  Rc,dR,d2R = logBarrierSquared(m::Vector, z::Vector, M::AbstractMesh,low::Vector,high::Vector, epsilon)\n\nComputes logBarrier regularizer\n\nR = (log(1 - ((m-high)/epsilon).^2))^2 if high-epsilon    m   high\n                0                      if low+epsilon   = m  = high-epsilon\n    (log(1 - ((m-low)/epsilon).^2))^2  if low             m   low+epsilon\n\nInput:\n    m       - model\n    z       - not being used. Here for compatibility.\n    M       - Mesh. not being used. Here for compatibility.\n    low     - low bound for each coordinate.\n    high    - high bound for each coordinate.\n    epsilon - layer width of the barier. \n\nOutput\n    g    - value of regularizer\n    dg    - gradient w.r.t. m\n    d2g   - Gauss Newton Hessian approximation (diagonal matrix). Second derivative approx is continous.  #  jInv.InverseSolve.projGNCG     Function .  mc,Dc,outerFlag = projGNCG(mc,pInv::InverseParam,pMis, indFor = [], dumpResults::Function = dummy)\n\n(Projected) Gauss-NewtonCG\n\nInput:\n\n    mc::Vector          - intial guess for model\n    pInv::InverseParam  - parameter for inversion\n    pMis                - misfit terms\n    indCredit           - indices of forward problems to work on\n    dumpResults         - A function pointer for saving the results throughout the iterations.\n                        - We assume that dumpResults is dumpResults(mc,Dc,iter,pInv,pMis), \n                        - where mc is the recovered model, Dc is the predicted data. \n                        - If dumpResults is not given, nothing is done (dummy() is called).\n    out::Int            - flag for output (-1: no output, 1: final status, 2: residual norm at each iteration)\n\nOutput:\n    mc                  - final model\n    Dc                  - data\n    outerFlag           - flag for convergence\n    His                 - iteration history  #  jInv.InverseSolve.projPCG     Function .  dm = projPCG(H,g,Active,Precond,cgTol,maxIter)\n\nProjected Preconditioned Conjugate Gradient method for solving\n\n    H*dm = g    subject to    dm[!Active] == 0 \n\nInput:\n\n    H::Function       -  computes action of Hessian\n    g::Vector         -  right hand side\n    Active            -  describes active cells\n    Precond::Function - preconditioner\n    cgTol             - tolerance\n    maxIter             - maximum number of iterations  #  jInv.InverseSolve.smallnessReg     Function .  Rc,dR,d2R = smallnessReg(m,mref,M,Iact=1.0)\n\nCompute smallness regularizer (L2 difference to reference model)\n\n    R(m) = 0.5*||m-mref||_V^2\n\nInput:\n    m     - model\n    mref  - reference model\n    M     - Mesh\n\nOutput\n    Rc    - value of regularizer\n    dR    - gradient w.r.t. m\n    d2R   - Hessian  #  jInv.InverseSolve.wTVReg     Function .  Rc,dR,d2R = wTVReg(m,mref,M,Iact,C=[])\n\nCompute weighted total variation regularizer\n\nInput:\n    m     - model\n    mref  - reference model\n    M     - Mesh\n    Iact  - projector on active cells\n    C     - anisotropy parameters (default: [1 1 1])\n    eps   - conditioning parameter for TV norm (default: 1e-3)\n\nOutput\n    Rc    - value of regularizer\n    dR    - gradient w.r.t. m\n    d2R   - Hessian  #  jInv.InverseSolve.wdiffusionRegNodal     Function .  Rc,dR,d2R = wdiffusionRegNodal(m::Vector, mref::Vector, M::AbstractMesh; Iact=1.0, C=[])\n\nComputes weighted diffusion regularizer for nodal model\n\nInput:\n    m     - model\n    mref  - reference model\n    M     - Mesh\n    Iact  - projector on active cells\n    C     - optional parameters\n\nOutput\n    Rc    - value of regularizer\n    dR    - gradient w.r.t. m\n    d2R   - Hessian", 
            "title": "jInv.InverseSolve"
        }, 
        {
            "location": "/ForwardShare/", 
            "text": "jInv.ForwardShare\n\n\nThe \nForwardShare\n submodule provides methods that are useful for different forward problems such as mesh-to-mesh interpolation, parallelization, etc. \n\n\n\n\nList of types and methods\n\n\n#\n\n\njInv.ForwardShare.getSensMatVec\n \n \nFunction\n.\n\n\nJv  = getSensMatVec(v::Vector,m::Vector,param::ForwardProbType)\n\n\nComputes matrix-vector product with the Jacobian.\n\n\n#\n\n\njInv.ForwardShare.getSensTMatVec\n \n \nFunction\n.\n\n\nJTv  = getSensMatVec(v::Vector,m::Vector,param::ForwardProbType)\n\n\nComputes matrix-vector product with the transpose of Jacobian. Implementation depends on forward problem.", 
            "title": "ForwardShare"
        }, 
        {
            "location": "/ForwardShare/#jinvforwardshare", 
            "text": "The  ForwardShare  submodule provides methods that are useful for different forward problems such as mesh-to-mesh interpolation, parallelization, etc.", 
            "title": "jInv.ForwardShare"
        }, 
        {
            "location": "/ForwardShare/#list-of-types-and-methods", 
            "text": "#  jInv.ForwardShare.getSensMatVec     Function .  Jv  = getSensMatVec(v::Vector,m::Vector,param::ForwardProbType)  Computes matrix-vector product with the Jacobian.  #  jInv.ForwardShare.getSensTMatVec     Function .  JTv  = getSensMatVec(v::Vector,m::Vector,param::ForwardProbType)  Computes matrix-vector product with the transpose of Jacobian. Implementation depends on forward problem.", 
            "title": "List of types and methods"
        }, 
        {
            "location": "/Utils/", 
            "text": "jInv.Utils\n\n\nThe \nUtils\n submodule provides some basic utility functions used in many parts of jInv. For example, it provides derivative testing and methods for clearing variables. \n\n\n\n\nList of methods", 
            "title": "Utils"
        }, 
        {
            "location": "/Utils/#jinvutils", 
            "text": "The  Utils  submodule provides some basic utility functions used in many parts of jInv. For example, it provides derivative testing and methods for clearing variables.", 
            "title": "jInv.Utils"
        }, 
        {
            "location": "/Utils/#list-of-methods", 
            "text": "", 
            "title": "List of methods"
        }
    ]
}